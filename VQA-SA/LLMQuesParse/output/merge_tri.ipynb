{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "from Portable import osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_base = r\"./entity/merged_entities.json\"\n",
    "depth_base = r\"./depth/entities_with_depth.json\"\n",
    "ref_ext_dir = r\"./ref_ext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(entities_base, \"r\", encoding=\"utf8\") as ent_reader,\\\n",
    "    open(depth_base, \"r\", encoding=\"utf8\") as dep_reader:\n",
    "    ent_data = json.load(ent_reader)\n",
    "    dep_data = json.load(dep_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基底字典 REC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ent_dict = dict()\n",
    "for ed in ent_data: base_ent_dict[(ed[\"image_name\"], ed[\"question\"])] = ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并深度 DEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "non_directions = list()\n",
    "for dd in dep_data: \n",
    "    key = (dd[\"image_name\"], dd[\"question\"])\n",
    "    if key not in base_ent_dict: non_directions.append(key); continue\n",
    "    base_ent_dict[key][\"depth\"] = dd[\"depth\"]\n",
    "print(non_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并参考 REF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6e7967c844404480c85f681c093610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3534032/4251247544.py:21: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  simis = [(o, ref.similarity(nlp(o))) for o in objects]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nullrefs: 396\n",
      "1277\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_md\")\n",
    "base_thresh = 0.5\n",
    "ref_pattern = r\"^参考：(.+)\\n类别：([^\\n]+)\"\n",
    "def parse_ref(\n",
    "        ser:str,\n",
    "        objects:list\n",
    "    ) -> Optional[dict]:\n",
    "    if not objects: return None\n",
    "    result = re.findall(ref_pattern, ser)\n",
    "    if not result: return None\n",
    "    result = result[0]\n",
    "    if result[0] == \"画面视角\": dref = result[0]\n",
    "    elif result[0] in objects: dref = result[0]\n",
    "    else: \n",
    "        ref = nlp(result[0])\n",
    "        simis = [(o, ref.similarity(nlp(o))) for o in objects]\n",
    "        simis = sorted(simis, key=lambda t: t[1], reverse=True)\n",
    "        if simis[0][1] < base_thresh: return None\n",
    "        dref = simis[0][0]\n",
    "    return {\n",
    "        \"ref\": dref,\n",
    "        \"cls\": result[1]\n",
    "    }\n",
    "\n",
    "non_directions = list(); nullref_counter = 0; nullrefs = list()\n",
    "for key in tqdm(base_ent_dict.keys()):\n",
    "    image_json = osp.j(ref_ext_dir, osp.refmt(key[0], \".json\"))\n",
    "    if not osp.exists(image_json): base_ent_dict[key][\"reference\"] = None; continue\n",
    "    question = key[1]\n",
    "    with open(image_json, \"r\", encoding=\"utf8\") as reader:\n",
    "        questions = json.load(reader)\n",
    "    for i, q in enumerate(questions): \n",
    "        if question == q[\"question\"]: break\n",
    "    else: non_directions.append(key); continue\n",
    "    objects = list(base_ent_dict[key][\"objects\"].keys())\n",
    "    parsed_ref = parse_ref(questions[i][\"parsed\"], objects)\n",
    "    if not parsed_ref: nullref_counter += 1; nullrefs.append([key, questions[i][\"parsed\"], objects])\n",
    "    base_ent_dict[key][\"reference\"] = parsed_ref\n",
    "    # break\n",
    "    \n",
    "print(f\"nullrefs: {nullref_counter}\")\n",
    "print(len(non_directions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nr in nullrefs: \n",
    "#     for e in nr: print(e)\n",
    "#     print(\"-\" * 100)\n",
    "err_dump = r\"./ref_rect.json\"\n",
    "with open(err_dump, \"w\", encoding=\"utf8\") as writer:\n",
    "    json.dump(nullrefs, writer, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path = r\"./merged_tri_infos.json\"\n",
    "seq_ref = r\"../sln/VQA_SA/VQA-SA-question.json\"\n",
    "seq_list = list()\n",
    "with open(seq_ref, \"r\", encoding=\"utf8\") as reader:\n",
    "    seq_data = json.load(reader)\n",
    "    for sd in seq_data: seq_list.append((sd[\"image_path\"].replace(\"images\\\\\", \"\"), sd[\"question\"]))\n",
    "dump_contents = list()\n",
    "for sle in seq_list: \n",
    "    if sle not in base_ent_dict: continue\n",
    "    dump_contents.append(base_ent_dict[sle])\n",
    "with open(dump_path, \"w\", encoding=\"utf8\") as writer:\n",
    "    json.dump(dump_contents, writer, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
