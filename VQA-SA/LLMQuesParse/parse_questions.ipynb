{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengzy/mambaforge/envs/qwen2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-24 18:24:47,645] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengzy/mambaforge/envs/qwen2/lib/python3.11/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @autocast_custom_fwd\n",
      "/home/pengzy/mambaforge/envs/qwen2/lib/python3.11/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @autocast_custom_bwd\n"
     ]
    }
   ],
   "source": [
    "import utils.message_constructor as mc\n",
    "import utils.vlm_utils as vu\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = r\"./sln/VQA_SA/VQA-SA-question.json\"\n",
    "llm_base = r\"./sln/qwen2.5_lm_7B\"\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path, \"r\", encoding=\"utf8\") as reader:\n",
    "    data = json.load(reader)\n",
    "if_dict = dict()\n",
    "key_seq = list()\n",
    "for e in data:\n",
    "    if e[\"image_path\"] not in if_dict:\n",
    "        if_dict[e[\"image_path\"]] = list()\n",
    "        key_seq.append(e[\"image_path\"])\n",
    "    if_dict[e[\"image_path\"]].append(e[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vlm based on <class 'transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM'> is loaded\n"
     ]
    }
   ],
   "source": [
    "vu.ensure_vl_base(\n",
    "    base_path=llm_base,\n",
    "    device=device,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = vu.vl_model\n",
    "llm_processor = vu.vl_processor\n",
    "\n",
    "def qwen25_infer(\n",
    "        messages:mc.Message,\n",
    "        max_new_tokens:int=vu.DEFAULT_MAX_NEW_TOKENS\n",
    "    ) -> str:\n",
    "    text = llm_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = llm_processor(text=[text], return_tensors=\"pt\")\n",
    "    inputs = inputs.to(llm_model.device)\n",
    "    generated_ids = llm_model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
    "    output_text = llm_processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    return \"\".join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "images\\26_2_104_0000029_240921.jpg\n",
      "1、身穿黄色衣服的男人位于穿花斑吊带女人的什么位置？请从前方、左方、右方、后方中选择一个回答\n",
      "2、位于近处桌上正放的杯子和手提包哪个所处的位置更高？请从杯子和手提包中选择一个回答\n",
      "3、位于近处桌上正放的杯子和手提包哪个离图片中间区域的风扇更远？请从杯子和手提包中选择一个回答\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils.prompts as sp\n",
    "\n",
    "chosen = key_seq[1567]\n",
    "print(chosen)\n",
    "\n",
    "def input_construct(ques_list:list) -> str:\n",
    "    ques_list = [f\"{(i + 1)}、{ques_list[i]}\" for i in range(len(ques_list))]\n",
    "    return \"\\n\".join(ques_list)\n",
    "\n",
    "user_utter = input_construct(if_dict[chosen])\n",
    "\n",
    "message = mc.Message().add_role_block(\"system\", sp.PARSER_SYSTEM)\\\n",
    "                .add_role_block(\"user\", user_utter)\n",
    "\n",
    "print(user_utter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"reference\": null,\n",
      "        \"observe\": [\"身穿黄色衣服的男人\", \"穿花斑吊带的女人\"],\n",
      "        \"options\": [\"前方\", \"左方\", \"右方\", \"后方\"]\n",
      "    },\n",
      "    {\n",
      "        \"reference\": null,\n",
      "        \"observe\": [\"杯子\", \"手提包\"],\n",
      "        \"options\": [\"杯子\", \"手提包\"]\n",
      "    },\n",
      "    {\n",
      "        \"reference\": null,\n",
      "        \"observe\": [\"杯子\", \"手提包\"],\n",
      "        \"options\": [\"杯子\", \"手提包\"]\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output = qwen25_infer(message, 2048)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
